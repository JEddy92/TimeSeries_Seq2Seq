{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/simple_trig.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df.sample(3, random_state=8)\n",
    "labels = sample['labels'].tolist()\n",
    "series_samples = sample[df.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_series(df, n_series):\n",
    "    \n",
    "    sample = df.sample(n_series, random_state=8)\n",
    "    labels = sample['labels'].tolist()\n",
    "    series_samples = sample[df.columns[1:]]\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    \n",
    "    for i in range(series_samples.shape[0]):\n",
    "        pd.Series(series_samples.iloc[i]).astype(np.float64).plot(linewidth=1.5)\n",
    "    \n",
    "    plt.title('Randomly Selected Data')\n",
    "    plt.legend(labels)\n",
    "    \n",
    "plot_random_series(df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_steps = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Dense, Dropout, Lambda, concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# convolutional layer parameters\n",
    "n_filters = 32 \n",
    "filter_width = 2\n",
    "# 6 is good for 512 input length\n",
    "dilation_rates = [2**i for i in range(6)] \n",
    "\n",
    "# define an input history series and pass it through a stack of dilated causal convolutions. \n",
    "history_seq = Input(shape=(None, 1))\n",
    "x = history_seq\n",
    "\n",
    "for dilation_rate in dilation_rates:\n",
    "    x = Conv1D(filters=n_filters,\n",
    "               kernel_size=filter_width, \n",
    "               padding='causal',\n",
    "               dilation_rate=dilation_rate)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Dense(1)(x)\n",
    "\n",
    "# extract the last 14 time steps as the training target\n",
    "def slice(x, seq_length):\n",
    "    return x[:,-seq_length:,:]\n",
    "\n",
    "pred_seq_train = Lambda(slice, arguments={'seq_length':14})(x)\n",
    "\n",
    "model = Model(history_seq, pred_seq_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_n_samples = 40000\n",
    "batch_size = 2**11\n",
    "epochs = 100\n",
    "\n",
    "all_series = df[df.columns[1:]].values\n",
    "series_mean = all_series.mean(axis=1).reshape(-1,1)\n",
    "all_series = all_series - series_mean\n",
    "\n",
    "encoder_input_data=all_series[:first_n_samples,:512].reshape(first_n_samples,-1,1)\n",
    "decoder_target_data=all_series[:first_n_samples,512+1-pred_steps:512+1].reshape(first_n_samples,-1,1)\n",
    "\n",
    "print(\"encoder_input_data.shape=\", encoder_input_data.shape)\n",
    "print(\"decoder_target_data.shape=\", decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), loss='mean_absolute_error')\n",
    "history = model.fit(encoder_input_data, decoder_target_data,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error Loss')\n",
    "plt.title('Loss Over Time')\n",
    "plt.legend(['Train','Valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(input_sequence):\n",
    "\n",
    "    history_sequence = input_sequence.copy()\n",
    "    pred_sequence = np.zeros((1,pred_steps,1)) # initialize output (pred_steps time steps)  \n",
    "    \n",
    "    for i in range(pred_steps):\n",
    "        \n",
    "        # record next time step prediction (last time step of model output) \n",
    "        last_step_pred = model.predict(history_sequence)[0,-1,0]\n",
    "        pred_sequence[0,i,0] = last_step_pred\n",
    "        \n",
    "        # add the next time step prediction to the history sequence\n",
    "        history_sequence = np.concatenate([history_sequence, \n",
    "                                           last_step_pred.reshape(-1,1,1)], axis=1)\n",
    "\n",
    "    return pred_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_samples = all_series.shape[0] - first_n_samples\n",
    "left_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 512 points, [0]-[511]\n",
    "test_input_data=all_series[first_n_samples:,:512].reshape(-1,512,1)\n",
    "# pred_steps points, [512]-[526]\n",
    "test_target_data=all_series[first_n_samples:,512:512+pred_steps].reshape(-1,pred_steps,1)\n",
    "\n",
    "print(\"test_input_data.shape=\", test_input_data.shape)\n",
    "print(\"test_target_data.shape=\", test_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(input_data, target_data, sample_ind, input_disp_len=50):\n",
    "    input_series = input_data[sample_ind,:,0].reshape(1,-1,1)\n",
    "    pred_series  = predict_sequence(input_series)\n",
    "    \n",
    "    input_series  = input_series.reshape(-1)\n",
    "    pred_series   = pred_series.reshape(-1)\n",
    "    target_series = target_data[sample_ind,:,:].reshape(-1)\n",
    "    \n",
    "    input_series_tail  = input_series[-input_disp_len:]\n",
    "    plt.figure(figsize =(10,6))   \n",
    "    \n",
    "    tail_range   = range(512-input_disp_len,512)\n",
    "    target_range = range(512+1,512+1+pred_steps)\n",
    "    pred_range   = target_range\n",
    "    plt.plot(tail_range,input_series_tail,linewidth=3)\n",
    "    plt.plot(target_range,target_series,color='orange')\n",
    "    plt.plot(target_range,pred_series,color='teal',linestyle='--')\n",
    "    \n",
    "    plt.title('Encoder Series Tail of Length %d, Target Series, and Predictions' % input_disp_len)\n",
    "    plt.legend(['Encoding Series','Target Series','Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_plot(test_input_data, test_target_data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_plot(test_input_data, test_target_data, 6007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_plot(test_input_data, test_target_data, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_plot(test_input_data, test_target_data, 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_plot(test_input_data, test_target_data, 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"simple_trig_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
